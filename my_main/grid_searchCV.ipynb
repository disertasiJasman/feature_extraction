{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmanpardede/Library/Python/3.6/lib/python/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/jasmanpardede/Library/Python/3.6/lib/python/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Best: 0.703125 using {'batch_size': 20, 'epochs': 100}\n",
      "0.598958 (0.020505) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.687500 (0.016877) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.699219 (0.027251) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.572917 (0.049855) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.647135 (0.022402) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.703125 (0.028705) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.569010 (0.077098) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.641927 (0.037377) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.647135 (0.038582) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.600260 (0.024774) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.643229 (0.011201) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.622396 (0.028940) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.548177 (0.123293) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.606771 (0.017566) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.632813 (0.033299) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.645833 (0.031948) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.572917 (0.051263) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.545573 (0.145787) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    # fix random seed for reproducibility\n",
    "    seed = 7\n",
    "    numpy.random.seed(seed)\n",
    "\n",
    "    # load dataset\n",
    "    dataset = numpy.loadtxt(\"../data-set/pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "    # split into input (X) and output (Y) variables\n",
    "    X = dataset[:,0:8]\n",
    "    Y = dataset[:,8]\n",
    "\n",
    "    # create model\n",
    "    model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "    # define the grid search parameters\n",
    "    batch_size = [10, 20, 40, 60, 80, 100]\n",
    "    epochs = [10, 50, 100]\n",
    "\n",
    "    param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "    grid_result = grid.fit(X, Y)\n",
    "\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
